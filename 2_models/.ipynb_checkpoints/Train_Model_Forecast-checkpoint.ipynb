{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Model\n",
    "\n",
    "In this notebook we'll train a deep learning model that learns if the target price or the stop loss would be hit for a long/short trade in the next hour based on the last two hours of price data.\n",
    "\n",
    "Model:\n",
    "* Multilayer Perceptron (MLP) (Feedforward neural network)\n",
    "* 3 layers: input (29), hidden (14), output (2)\n",
    "* Binary Classification\n",
    "* `Input`: Time, Open, Low, High, Close, SMA(5 to 60 min), ROC(5 to 60 min)\n",
    "* `Output`: Does a long or short trade hit the profit target (20 points) without hitting a stop loss (10 points) in the next hour? No=0,Yes=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"long_short_predict\"\n",
    "\n",
    "with open(\"model/model_name\", \"w\") as text_file:\n",
    "    text_file.write(model_name)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../0_data/INTC.csv\",infer_datetime_format=True, parse_dates=['dt'], index_col=['dt'])\n",
    "df.to_csv('local_test/test_dir/input/data/training/data_orig.csv')\n",
    "print(\"count=%s\" % len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "df[\"close\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Run Data Preparation Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Data Preparation Code\n",
    "\n",
    "In the following cell, you can modify the data preparation code or leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/data_prep_long_short_predict.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib as ta\n",
    "from talib.abstract import *\n",
    "import math\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "input_path = prefix + 'input/data/training'\n",
    "\n",
    "data_orig_file = input_path+'/data_orig.csv'\n",
    "data_file = input_path+'/data.csv'\n",
    "\n",
    "d = pd.read_csv(data_orig_file,infer_datetime_format=True, parse_dates=['dt'], index_col=['dt'])\n",
    "print(d.head())\n",
    "\n",
    "repeatCount=6\n",
    "repeatStep=5\n",
    "lookBack=repeatCount*repeatStep\n",
    "forwardWindow=5\n",
    "\n",
    "profitTarget=0.02\n",
    "stopTarget=0.01\n",
    "\n",
    "iCount=lookBack\n",
    "\n",
    "# header\n",
    "hData=[\"dt\"]\n",
    "hData.append(\"close\")\n",
    "for a in range(0,repeatCount):\n",
    "    hData.append(\"sma\"+str((a+1)*repeatStep))\n",
    "for a in range(0,repeatCount):\n",
    "    hData.append(\"roc\"+str((a+1)*repeatStep))\n",
    "hData.append(\"long\")\n",
    "hData.append(\"short\")\n",
    "\n",
    "# data\n",
    "tData=[]\n",
    "\n",
    "inputs = {\n",
    "    'close': np.array(d[\"close\"])\n",
    "}\n",
    "sma=[]\n",
    "for a in range(0,repeatCount):\n",
    "    sma.append(SMA(inputs,timeperiod=(a+1)*repeatStep))\n",
    "roc=[]\n",
    "for a in range(0,repeatCount):\n",
    "    roc.append(ROC(inputs,timeperiod=(a+1)*repeatStep))\n",
    "\n",
    "closeList=d[\"close\"]\n",
    "dLen=len(d)\n",
    "n=0\n",
    "lCount=0\n",
    "sCount=0\n",
    "nCount=0\n",
    "\n",
    "for idx,row in d.iterrows():\n",
    "    if n>=iCount-1:\n",
    "        dt1=idx\n",
    "        cl=row[\"close\"]\n",
    "        inputRec=[]\n",
    "        inputRec.append(idx)\n",
    "\n",
    "        inputRec0=[]\n",
    "\n",
    "        #close\n",
    "        inputRec0.append(cl)\n",
    "\n",
    "        #sma\n",
    "        for a in range(0,repeatCount):\n",
    "            if math.isnan(sma[a][n]):\n",
    "                inputRec0.append(cl)\n",
    "            else:\n",
    "                inputRec0.append(sma[a][n])\n",
    "\n",
    "        m1=min(inputRec0)\n",
    "        m2=max(inputRec0)\n",
    "\n",
    "        for a in inputRec0:\n",
    "            if m2-m1==0:\n",
    "                inputRec.append(0)\n",
    "            else:\n",
    "                inputRec.append((a-m1)/(m2-m1))\n",
    "\n",
    "        #roc\n",
    "        for a in range(0,repeatCount):\n",
    "            if math.isnan(roc[a][n]):\n",
    "                inputRec.append(0)\n",
    "            else:\n",
    "                inputRec.append(roc[a][n])\n",
    "\n",
    "        rClose=closeList[n:min(dLen,n+forwardWindow)]\n",
    "        maxClose=max(rClose)\n",
    "        minClose=min(rClose)\n",
    "\n",
    "        #long/short\n",
    "        long=0\n",
    "        if maxClose-cl>=cl*(1+profitTarget) and not cl-minClose>=cl*(1+stopTarget):\n",
    "            long=1\n",
    "            lCount=lCount+1\n",
    "        inputRec.append(long)\n",
    "        short=0\n",
    "        if cl-minClose>=cl*(1+profitTarget) and not maxClose-cl>=cl*(1+stopTarget):\n",
    "            short=1\n",
    "            sCount=sCount+1\n",
    "        inputRec.append(short)\n",
    "        if long==0 and short==0:\n",
    "            nCount=nCount+1\n",
    "\n",
    "        tData.append(inputRec)\n",
    "          \n",
    "print(\"lCount=%s,sCount=%s,nCount=%s\" % (lCount,sCount,nCount))\n",
    "df1=pd.DataFrame(tData,columns=hData)\n",
    "df1.set_index(pd.DatetimeIndex(df1['dt']), inplace=True)\n",
    "del df1['dt']\n",
    " \n",
    "df1.to_csv(data_file)\n",
    "print(df1.head(5))\n",
    "print(\"count=%s\" % (len(df1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Data Preparation Locally in a Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp model/data_prep_$(cat model/model_name).py model/train\n",
    "!chmod 777 model/train\n",
    "!docker build -t data_prep_$(cat model/model_name) .\n",
    "!docker run -v $(pwd)/local_test/test_dir:/opt/ml --rm data_prep_$(cat model/model_name) train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"local_test/test_dir/input/data/training/data.csv\",infer_datetime_format=True, parse_dates=['dt'], index_col=['dt'])\n",
    "print(\"totalCount=%s\" % len(df))\n",
    "\n",
    "trainCount=int(len(df)*0.3)\n",
    "dfTrain = df.iloc[:trainCount]\n",
    "dfTrain.to_csv('local_test/test_dir/input/data/training/data_train.csv')\n",
    "print(\"trainCount=%s\" % len(dfTrain))\n",
    "\n",
    "dfTest = df.iloc[trainCount:]\n",
    "dfTest.to_csv('local_test/test_dir/input/data/training/data_test.csv')\n",
    "print(\"testCount=%s\" % len(dfTest))\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) Train the Model\n",
    "\n",
    "In the following cell, you can modify the model training code or leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/model_long_short_predict.py\n",
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "yLen=2\n",
    "b=0\n",
    "\n",
    "# Optional\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your\n",
    "# container.\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data/training/data_train.csv'\n",
    "test_path = prefix + 'input/data/training/data_test.csv'\n",
    "\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "\n",
    "# Process and prepare the data\n",
    "def data_process(df):\n",
    "    global yLen\n",
    "    global b\n",
    "    dataX=[]\n",
    "    dataY=[]\n",
    "    for idx,row in df.iterrows():\n",
    "        row1=[]\n",
    "        r=row[1:len(row)-yLen]\n",
    "        for a in r:\n",
    "            row1.append(a)\n",
    "        x=np.array(row1)\n",
    "        y=np.array(row[len(row)-yLen:])\n",
    "        b=len(x)\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "    dataX=np.array(dataX)\n",
    "    dataY=np.array(dataY)\n",
    "    return dataX,dataY,b\n",
    "\n",
    "def build_classifier():\n",
    "    global b\n",
    "    global yLen\n",
    "    print(\"build_classifier:b=%s,yLen=%s\" % (b,yLen))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(b, input_dim=b, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(int(b/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(yLen,kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def generate_model(dataX, dataY, b):\n",
    "    model=build_classifier()\n",
    "    model.fit(dataX, dataY, epochs=100, batch_size=15)\n",
    "    scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "    print(\"Training Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    return model\n",
    "        \n",
    "def train():\n",
    "    print('Starting the training.')\n",
    "    try:\n",
    "        raw_data = pd.read_csv(input_path)\n",
    "        #print(raw_data)\n",
    "        X, y, b = data_process(raw_data)\n",
    "        model = generate_model(X, y, b)\n",
    "        model.save(os.path.join(model_path, 'model.h5'))\n",
    "        \n",
    "        print('Training is complete. Model saved.')\n",
    "        \n",
    "        raw_data = pd.read_csv(test_path)\n",
    "        testX, testY, b = data_process(raw_data)\n",
    "        scores = model.evaluate(testX, testY, verbose=0)\n",
    "        print(\"Test Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failure\n",
    "        # Reason in the DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs\n",
    "        print(\n",
    "            'Exception during training: ' + str(e) + '\\n' + trc,\n",
    "            file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Train Locally\n",
    "\n",
    "You can choose if you want to do the training locally (Option 1) or remote via SageMaker (Option 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Local ML Image\n",
    "!echo $(cat model/model_name) \n",
    "!cp model/model_$(cat model/model_name).py model/train\n",
    "!chmod 777 model/train\n",
    "!docker build -t model_$(cat model/model_name) .\n",
    "!docker run -v $(pwd)/local_test/test_dir:/opt/ml --rm model_$(cat model/model_name) train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Model Artifact to Strategies Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp local_test/test_dir/model/model.h5 ../strategies/model/model_$(cat model/model_name).h5\n",
    "!ls -la ../strategies/model/model_*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Remote Training via SageMaker\n",
    "\n",
    "You can choose if you want to do the training locally (Option 1) or remote via SageMaker (Option 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy ML Image to ECS\n",
    "!./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "model_name=''\n",
    "with open('model/model_name', 'r') as file:\n",
    "    model_name = file.read().replace('\\n', '')\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = 'local_test/test_dir/input/data/training'\n",
    "prefix = 'model_'+model_name\n",
    "job_name=prefix.replace('_','-')\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix='data')\n",
    "print(data_location)\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = f'{account}.dkr.ecr.{region}.amazonaws.com/{prefix}:latest'\n",
    "\n",
    "classifier = sage.estimator.Estimator(\n",
    "    image_name=image,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "    sagemaker_session=sess,\n",
    "    base_job_name=job_name)\n",
    "classifier.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Model Artifact from Amazon S3 and copy it to Strategies Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Model from S3\n",
    "model_name=classifier.model_data.replace('s3://'+sess.default_bucket()+'/','')\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sess.default_bucket())\n",
    "my_bucket.download_file(model_name,'model.tar.gz')\n",
    "!tar -xzf model.tar.gz\n",
    "!rm model.tar.gz\n",
    "!cp model.h5 ../strategies/model/model_$(cat model_name).h5\n",
    "!ls -la ../strategies/model/model_*.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
